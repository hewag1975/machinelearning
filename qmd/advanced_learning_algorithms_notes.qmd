---
title: "Notes advanced learning algorithms"
format: html
editor: source
editor_options: 
  chunk_output_type: console
engine: knitr
---

```{r}
knitr::opts_knit$set(
  root.dir = '~/Documents/repos/github/machinelearning'
)
```


## Neural networks

* neural networks = deep learning algorithms
* inference: take a pre-trained NN and make predictions
* traditional algorithms (linear, logistic regression) do not scale with amount of data
* activation function takes input and creates output, e.g. by logistic regression
* layer: group of n neurons (1..n), connected to the same input features
* output layer: final layer delivering the output
* input layer: first layer with features
* hidden layer: combines inputs from earlier layers to new features
* input $x$, activation $a$
* activations: logistic regressions that generate new features
* activations: higher level features
* architecture: number of hidden layers and hidden units per layer
* "multilayer perceptron": NN with multiple hidden layers


### Notation

* $a^l=g(w^l_j*a^{l-1}+b^l_j)$
* $a$ is the activation
* $l$ is the layer
* $j$ is the unit / neuron

* inference = making predictions, aka forward propagation


### Efficient implementation

* dot product
* matrix notation, transpose
* matrix multiplication
* in Python `np.matmul` or `@`


### Predicting from a NN in tensorflow

* create the model, i.e. define layers (architecture)
* load pre-calculated weights
* run prediction


### Training a NN in tensorflow

* create the model, i.e. define layers (architecture)
* define cost function, e.g. binary crossentropy
* train with a max number of epochs, i.e. minimize cost function $J(w,b)$
* training = back-propagation


### Binary crossentropy loss

* binary classification problem
* same as logistic loss $L(f(x),y)=-ylog(f(x))-(1-y)log(1-f(x))$
* other loss function in tensorflow: mean squared error (regression problem)


### Activation functions

* linear activation $g(z)=z$ (aka no activation)
* sigmoid activation $g(z)=\frac{1}{1+e^{-z}}$
* rectify linear unit `ReLU` function $g(z) = max(0, z)$
* softmax activation 

Choosing activation functions:

* output layer:

  * binary prediction: sigmoid
  * regression: linear activation
  * non-negative predictions: ReLU
  * multi-class ouptut: softmax
  
* hidden layers:

  * most common activation today is ReLU 
  * ReLU is faster than sigmoid
  * cost function for sigmoid is harder to minimize 
  
Need of activation functions:

* output: linear, hidden: linear: simplifies to linear regression
* output: sigmoid, hidden: linear: simplifies to logistic regression
* linear function of linear function is also a linear function
* never use linear activation in hidden layers


### Multiclass classification

* MNIST example 
* softmax regression
* example of four outputs (1..4):

  * calculate $z_1, z_2, z_3, z_4$, e.g. $z_1=w_1*x+b_1$
  * calculate $a_1, a_2, a_3, a_4$, e.g. $a_1=\frac{e^{z_1}}{\Sigma_{i=1}^4 e^{z_i}}$
  * general form: $z_j=w_j*x+b$, followed by $a_j=\frac{e^{z_j}}{\Sigma_{k=1}^j e^{z_k}}$
  * with $a_j=P(y=j|x)$ 
  
* loss function (crossentropy loss):

$$
L(a_1, ..., a_N, y)=
\begin{cases}
-log(a_1), \text{ if } y = 1 \\
-log(a_2), \text{ if } y = 2 \\
... \\
-log(a_N), \text{ if } y = N \\
\end{cases}
$$
* architecture of softmax with n classes requires output layer with n units
* softmax is unique as output in one output node depends on output of all other 
output nodes
* loss function is called `SparseCategoricalCrossentropy` in tensorflow 
* use argument `from_logits=True` when defining loss for dealing with roundup errors
* this requires the output layer to use linear activation (i.e. returning $z$) and calculate
probabilities afterwards using the sigmoid function ($g(z)$)


### Multilabel classification

* frequently used in image analysis
* multiple labels per image (e.g. car, bus, pedestrian, building)
* possible approaches:

  * define multiple networks, one per label
  * define one network with three outputs (output layer with three units) and 
  sigmoid activations
  
  
### Advanced optimization

* "Adam algorithm", adjusts $\alpha$ automatically to be smaller or larger
* Adam = Adaptive Moment estimation
* also $\alpha$ is different per $w$, i.e. $\alpha_j$
* only requires an initial learning rate
* Adam is more robust to learning rate
* de facto standard in NN training


### Additional layer types

* dense layer     
  
  * all activations from the previous layer are submitted to every neuron
  * i.e. every neurons output is a function of all activations 
  
* convolutional layer 

  * only a subset of activations from the previous layer is submitted to each neuron
  * i.e. each neurons output is a function of a subset of activations 
  * faster computation
  * need less training data
  * many choices regarding architecture (size of subsets)


### Back propagation 

* back propagation is an algorithm used to efficiently calculate derivatives
* computation graphs are used to simplify the operation 


## Model evaluation

* evaluate model performance by train-test-split
* compare train error $J$ with test error
* calculate cost $J_{train}$ for train and $J_{test}$ for test set (regression, 
classification)
* calculate fraction of misclassified observations in train and test 
(classification)
* cross-validation approach: split data into training, cross-validation (aka 
validation set or development set or dev set) and test set
* cross-validation approach is recommended if additional parameters are 
optimized (e.g. degree of a polynomial, number of layers in a NN, ...)
* error is same as cost except the regularization term
* test set is only used for estimating the generalization error


## Bias and variance

* high bias, low variance = underfit
* high variance, low bias = overfit
* high $J_{train}$ AND $J_{train} \approx J_{cv}$: high bias 
* low $J_{train}$ AND $J_{cv} >> J_{train}$: high variance 
* low $J_{train}$ AND $J_{train} \approx J_{cv}$: 'just right'
* high $J_{train}$ AND $J_{train} >> J_{cv}$: high bias AND high variance, i.e. 
model may overfit some parts of the training data and not fit other parts

* evaluating bias and variance in cross-validation is used to tune hyperparameters, 
e.g. $\lambda$ in regularized models
* plot cost $J_{train}$ and $J_{cv}$ as a function of $\lambda$
* baseline level of performance is helpful to evaluate $J_{train}$
* options for getting a baseline level:

  * human level performance
  * competing algorithm performance
  * experienced guess


## Learning curves

* plot $J_{train}$ and $J_{cv}$ versus training set size
* general patterns

  * usually $J_{cv}$ **decreases** with increasing training size
  * usually $J_{train}$ **increases** with increasing training size 
  * $J_{cv} > J_{train}$
  * sample of 1, 2, 3, ... is easier to fit than 1000

* high bias example

  * usually $J_{cv}$ **decreases** with increasing training size
  * usually $J_{train}$ **increases** with increasing training size 
  * $J_{cv} > J_{train}$
  * overall level of $J_{cv}, J_{train}$ is high
  * difference to baseline (human level) is large
  * adding more data will not help 

* high variance example

  * usually $J_{cv}$ **decreases** with increasing training size
  * usually $J_{train}$ **increases** with increasing training size 
  * $J_{cv} >> J_{train}$
  * huge gap between $J_{cv}, J_{train}$
  * baseline (human level) is in between, i.e. $J_{train}$ is better than baseline
  * adding more data will help 
  
  
## Debugging models

fix high variance problems:

* add more training data
* reduce features
* increase $\lambda$

fix high bias problems:

* add features
* add polynomial features
* decrease $\lambda$


## Bias and variance in NN

* large NN have typically low bias 
* recipe:

  * evaluate $J_{train}$ 

    * high $J_{train}$: increase NN (more layers, more neurons)
    * low $J_{train}$: evaluate $J_{cv}$
  
      * high $J_{cv}$: add data, start over again
      * low $J_{cv}$: done

* limitations:

  * large NN architectures require GPUS
  * more data sometimes expensive

* large NN will usually do better than a smaller one of regularized


## ML development process

* iterative loop in ML: choose architecture (model, data, etc.), train model, run 
diagnostics (bias, variance, error analysis), start over
* error analysis: inspect misclassifications / large errors (sample) and try to 
create categories and the prioritize activities to fix large categories

Adding data:

* focus in results of error analysis
* data augmentation:

  * mirror, enlarge, shrink, warping, ...
  * frequently applied in images classification, speech recognition
  * augmentation should be representative for unseen / test data 
  
* data synthesis:

  * use case: OCR (object character recognition)
  * create text in text editor and screenshot

* model-centric approach: AI = **Code** + Data
* code has been focused on heavily in the past
* data-centric approach: AI = Code + **Data**


## Transfer learning

* take pre-trained NN (images, audio, text)
* pre-trained NN: NN with supervised pre-training on large datasets
* fine tune NN on own data
* option 1: only train parameters of output layer
* option 2: use trained parameters to initialize a new NN
* large number of pre-trained models available
* input needs to be designed same way as for the pre-trained NN


## Cycle of a ML project

* from training to production 
* deploy plus monitor plus maintain
* example

  * mobile app calls server via API
  * server returns predictions
  
* software engineering required for reliable predictions, for scaling, logging, 
system monitoring, model updates
* practice of deployment and system maintenance: MLOps


## Ethics, fairness, bias

* bias: Discrimination against certain people (hiring, loans, negative 
stereotypes)
* unethical: deepfakes, adverse use cases, spreading toxic speech, fake use cases
* guidelines:

  * get a diverse team to brainstorm things that might go wrong (focus on harm)
  * literature search on guidelines for industry
  * audit systems against possible harms prior to deployment
  * develop a mitigation plan (e.g. rollback to earlier system) in case of harms


## Skewed datasets

* precision / recall instead of error / accuracy
* tradeoff between precision and recall
* precision versus recall plot
* F1 score: $\frac{1}{\frac{1}{2}(\frac{1}{P}+\frac{1}{R})}=2*\frac{PR}{P+R}$
* F1 score is harmonic mean of P and R

* ROC and AUC







